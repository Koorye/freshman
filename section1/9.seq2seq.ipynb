{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "MAX_LENGTH = 10 # Maximum sentence length\n",
    "\n",
    "# 默认的词向量\n",
    "PAD_token = 0 # Used for padding short sentences\n",
    "SOS_token = 1 # Start-of-sentence token\n",
    "EOS_token = 2 # End-of-sentence token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voc对象用于提供单词和索引的映射，以及单词总数。\n",
    "此外， `normalizeString`函数将字符串中所有字符转小写并删除非字母字符，`indexesFromSentence`函数接受一个单词的句子并返回相应单词索引序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # 统计SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "        keep_words = []\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # 统计默认的令牌\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)\n",
    "\n",
    "# 小写并删除非字母字符\n",
    "def normalizeString(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "# 使用字符串句子，返回单词索引的句子\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # 初始化GRU;input_size和hidden_size参数都设置为'hidden_size'\n",
    "        # 因为我们输入的大小是一个有多个特征的词向量== hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # 将单词索引转换为向量\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # 为RNN模块填充批次序列\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # 正向通过GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # 打开填充\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # 将双向GRU的输出结果总和\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # 返回输出以及最终的隐藏状态\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意力模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luong的注意力层\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # 根据给定的方法计算注意力权重（能量）\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # 转置max_length和batch_size维度\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # 返回softmax归一化概率分数（增加维度）\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # 保持参考\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # 定义层\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # 注意：我们这步只运行一次\n",
    "        # 获取当前输入字对应的向量映射\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # 通过单向GRU转发\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # 通过当前GRU的输出计算注意力权重\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # 注意力权重乘以编码器输出以获得新的“加权和”上下文向量\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # 使用Luong的公式5来连接加权上下文向量和GRU输出\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # 使用Luong的公式6来预测下一个单词\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # 返回输出和最终的隐藏状态\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贪婪搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(torch.jit.ScriptModule):\n",
    "    def __init__(self, encoder, decoder, decoder_n_layers):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self._device = device\n",
    "        self._SOS_token = SOS_token\n",
    "        self._decoder_n_layers = decoder_n_layers\n",
    "\n",
    "        constants = ['_device', '_SOS_token', '_decoder_n_layers']\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def forward(self,\n",
    "                input_seq: torch.Tensor,\n",
    "                input_length: torch.Tensor,\n",
    "                max_length: int):\n",
    "        # 通过编码器模型转发输入\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # 准备编码器的最终隐藏层作为解码器的第一个隐藏输入\n",
    "        decoder_hidden = encoder_hidden[:self._decoder_n_layers]\n",
    "        # 使用SOS_token初始化解码器输入\n",
    "        decoder_input = torch.ones(\n",
    "            1, 1, device=self._device, dtype=torch.long) * self._SOS_token\n",
    "        # 初始化张量以将解码后的单词附加到\n",
    "        all_tokens = torch.zeros([0], device=self._device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=self._device)\n",
    "        # 一次迭代地解码一个词令牌\n",
    "        for _ in range(max_length):\n",
    "            # 正向通过解码器\n",
    "            decoder_output, decoder_hidden = self.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # 获得最可能的单词标记及其softmax分数\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # 记录令牌和分数\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # 准备当前令牌作为下一个解码器输入（添加维度）\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # 返回词令牌和分数的集合\n",
    "        return all_tokens, all_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    # 格式化输入句子作为批处理\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # 创建长度张量\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # 转置批量的维度以匹配模型的期望\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # 使用适当的设备\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # 用earcher解码句子s\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "# 评估来自用户输入的输入(stdin)\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # 获取输入的句子\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # 规范化句子\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # 评估句子\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # 格式化和打印回复句\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")\n",
    "\n",
    "# 规范化输入句子并调用evaluate()\n",
    "def evaluateExample(sentence, encoder, decoder, searcher, voc):\n",
    "    print(\"> \" + sentence)\n",
    "    # 规范化句子\n",
    "    input_sentence = normalizeString(sentence)\n",
    "    # 评估句子\n",
    "    output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "    output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "    print('Bot:', ' '.join(output_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(\"../data\", \"save\")\n",
    "corpus_name = \"cornell movie-dialogs corpus\"\n",
    "\n",
    "# 配置模型\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# 如果你加载的是自己的模型\n",
    "# 设置要加载的检查点\n",
    "checkpoint_iter = 4000\n",
    "# loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                             '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                             '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "# 如果你加载的是托管模型\n",
    "loadFilename = '../data/4000_checkpoint.tar'\n",
    "\n",
    "# 加载模型\n",
    "# 强制CPU设备选项（与本教程中的张量匹配）\n",
    "checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "encoder_sd = checkpoint['en']\n",
    "decoder_sd = checkpoint['de']\n",
    "encoder_optimizer_sd = checkpoint['en_opt']\n",
    "decoder_optimizer_sd = checkpoint['de_opt']\n",
    "embedding_sd = checkpoint['embedding']\n",
    "voc = Voc(corpus_name)\n",
    "voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# 初始化词向量\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "embedding.load_state_dict(embedding_sd)\n",
    "# 初始化编码器和解码器模型\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "# 加载训练模型参数\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "decoder.load_state_dict(decoder_sd)\n",
    "# 使用适当的设备\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "# 将dropout层设置为eval模式\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型转脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1311\\scoop\\apps\\miniconda3\\current\\envs\\sci\\lib\\site-packages\\torch\\_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten\\src\\ATen/core/TensorBody.h:417.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "### 转换编码器模型\n",
    "# 创建人工输入\n",
    "test_seq = torch.LongTensor(MAX_LENGTH, 1).random_(0, voc.num_words).to(device)\n",
    "test_seq_length = torch.LongTensor([test_seq.size()[0]]).to(device)\n",
    "# 跟踪模型\n",
    "traced_encoder = torch.jit.trace(encoder, (test_seq, test_seq_length))\n",
    "\n",
    "### 转换解码器模型\n",
    "# 创建并生成人工输入\n",
    "test_encoder_outputs, test_encoder_hidden = traced_encoder(test_seq, test_seq_length)\n",
    "test_decoder_hidden = test_encoder_hidden[:decoder.n_layers]\n",
    "test_decoder_input = torch.LongTensor(1, 1).random_(0, voc.num_words)\n",
    "# 跟踪模型\n",
    "traced_decoder = torch.jit.trace(decoder, (test_decoder_input, test_decoder_hidden, test_encoder_outputs))\n",
    "\n",
    "### 初始化searcher模块\n",
    "scripted_searcher = GreedySearchDecoder(traced_encoder, traced_decoder, decoder.n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> hello\n",
      "Bot: hello .\n",
      "> what's up?\n",
      "Bot: i m going to get my car .\n",
      "> who are you?\n",
      "Bot: i m the owner .\n",
      "> where am I?\n",
      "Bot: in the house .\n",
      "> where are you from?\n",
      "Bot: south america .\n"
     ]
    }
   ],
   "source": [
    "# 评估例子\n",
    "sentences = [\"hello\", \"what's up?\", \"who are you?\", \"where am I?\", \"where are you from?\"]\n",
    "for s in sentences:\n",
    "    evaluateExample(s, traced_encoder, traced_decoder, scripted_searcher, voc)\n",
    "\n",
    "# 评估你的输入\n",
    "# evaluateInput(traced_encoder, traced_decoder, scripted_searcher, voc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1ffccd224b674281b661d8453c9f4a50fda620a54816bd52ce799644ce8ed04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('sci': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
